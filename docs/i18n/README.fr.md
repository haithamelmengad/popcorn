<p align="center">
  <a href="../../README.md">ğŸ“– English</a> â€¢
  <a href="../../LICENSE">âš–ï¸ License</a>
</p>

<h1 align="center">
  <br>
  ğŸ¿
  <br>
  popcorn
  <br>
</h1>

<h4 align="center">SystÃ¨me d'analyse vidÃ©o conÃ§u pour <a href="https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/overview" target="_blank">Claude Code</a>.</h4>

<p align="center">
  <a href="../../LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License">
  </a>
  <a href="../../package.json">
    <img src="https://img.shields.io/badge/version-0.4.0-green.svg" alt="Version">
  </a>
  <a href="https://modelcontextprotocol.io">
    <img src="https://img.shields.io/badge/MCP-Compatible-purple.svg" alt="MCP Compatible">
  </a>
</p>

<p align="center">
  Popcorn permet aux agents IA de regarder et comprendre des vidÃ©os longues en extrayant les transcriptions, dÃ©tectant les changements de scÃ¨ne et retournant les images clÃ©s. Tout fonctionne localementâ€”pas d'API externe, pas de frais, confidentialitÃ© totale.
</p>

---

## ğŸš€ DÃ©marrage Rapide

```bash
# Installer FFmpeg (requis)
brew install ffmpeg                    # macOS
sudo apt install ffmpeg                # Ubuntu/Debian

# Installer Popcorn
git clone https://github.com/anthropics/popcorn.git
cd popcorn && npm install && npm run build

# Optionnel: Installer un backend de transcription
pip install mlx-whisper                # Apple Silicon (le plus rapide)
pip install openai-whisper             # Toute plateforme
```

**FonctionnalitÃ©s ClÃ©s:**

- ğŸ¬ **DÃ©tection de ScÃ¨nes** â€” Capture les images aux transitions visuelles, pas Ã  intervalles fixes
- ğŸ¤ **Transcription Locale** â€” 4 options de backend
- ğŸ–¼ï¸ **Images en Ligne** â€” Retourne les images clÃ©s directement dans les rÃ©ponses MCP
- ğŸ¯ **PrÃ©rÃ©glages Intelligents** â€” Configure automatiquement pour screencasts, prÃ©sentations, films, interviews
- âš¡ **ZÃ©ro Configuration** â€” Passez simplement le chemin de la vidÃ©o
- ğŸ”’ **ConfidentialitÃ© d'Abord** â€” Tout fonctionne localement, les donnÃ©es ne quittent pas votre machine

---

## ğŸ¤ Backends de Transcription

| Backend | Vitesse | IdÃ©al Pour | Installation |
|---------|---------|------------|--------------|
| **mlx-whisper** | âš¡âš¡âš¡âš¡ | Apple Silicon | `pip install mlx-whisper` |
| **faster-whisper** | âš¡âš¡âš¡âš¡ | GPUs NVIDIA | `pip install faster-whisper` |
| **whisper-cpp** | âš¡âš¡âš¡ | Multiplateforme | `brew install whisper-cpp` |
| **whisper** | âš¡âš¡ | Plus compatible | `pip install openai-whisper` |

---

## ğŸ“„ Licence

Licence MIT â€” voir [LICENSE](../../LICENSE) pour les dÃ©tails.

---

<p align="center">
  Fait avec ğŸ¿ pour les agents IA partout
</p>
